import type { VercelRequest, VercelResponse } from '@vercel/node';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;
const supabase = createClient(supabaseUrl, supabaseServiceKey);

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!
});

interface OptimizationRequest {
  content: string;
  platform: string;
  objective: 'engagement' | 'reach' | 'conversions' | 'brand_awareness';
  targetAudience?: string;
  contentType?: string;
  tone?: string;
  includeHashtags?: boolean;
  maxLength?: number;
}

interface OptimizationResult {
  originalContent: string;
  optimizedContent: string;
  improvements: {
    type: string;
    change: string;
    reason: string;
  }[];
  platformSpecificOptimizations: {
    hashtags: string[];
    mentions: string[];
    emoji: string[];
    callToAction: string;
  };
  expectedImprovements: {
    engagementIncrease: number;
    reachIncrease: number;
    confidenceScore: number;
  };
  alternativeVersions: {
    title: string;
    content: string;
    focus: string;
  }[];
  seoOptimizations: {
    keywords: string[];
    readabilityScore: number;
    sentimentScore: number;
  };
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const authHeader = req.headers.authorization;
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ error: 'Missing or invalid authorization header' });
    }

    const token = authHeader.split(' ')[1];
    const { data: { user }, error: userError } = await supabase.auth.getUser(token);
    
    if (userError || !user) {
      return res.status(401).json({ error: 'Invalid user token' });
    }

    const optimizationRequest: OptimizationRequest = req.body;

    if (!optimizationRequest.content || !optimizationRequest.platform) {
      return res.status(400).json({ error: 'Missing content or platform' });
    }

    // Perform content optimization
    const optimization = await optimizeContent(optimizationRequest);

    // Store optimization result
    await supabase
      .from('content_optimizations')
      .insert({
        user_id: user.id,
        original_content: optimizationRequest.content,
        optimized_content: optimization.optimizedContent,
        platform: optimizationRequest.platform,
        objective: optimizationRequest.objective,
        optimization_result: optimization,
        created_at: new Date().toISOString()
      });

    res.status(200).json({
      success: true,
      optimization,
      optimizedAt: new Date().toISOString()
    });

  } catch (error) {
    console.error('Content optimization error:', error);
    res.status(500).json({ 
      error: 'Optimization failed', 
      details: error instanceof Error ? error.message : 'Unknown error'
    });
  }
}

async function optimizeContent(request: OptimizationRequest): Promise<OptimizationResult> {
  const {
    content,
    platform,
    objective,
    targetAudience = 'general',
    contentType = 'post',
    tone = 'professional',
    includeHashtags = true,
    maxLength
  } = request;

  // 1. Generate optimized content using AI
  const optimizedContent = await generateOptimizedContent(request);
  
  // 2. Generate platform-specific optimizations
  const platformOptimizations = await generatePlatformOptimizations(content, platform, includeHashtags);
  
  // 3. Generate alternative versions
  const alternativeVersions = await generateAlternativeVersions(content, platform, objective);
  
  // 4. Calculate expected improvements
  const expectedImprovements = await calculateExpectedImprovements(content, optimizedContent, platform);
  
  // 5. Generate SEO optimizations
  const seoOptimizations = await generateSEOOptimizations(optimizedContent);
  
  // 6. Identify specific improvements made
  const improvements = identifyImprovements(content, optimizedContent, platform);

  return {
    originalContent: content,
    optimizedContent,
    improvements,
    platformSpecificOptimizations: platformOptimizations,
    expectedImprovements,
    alternativeVersions,
    seoOptimizations
  };
}

async function generateOptimizedContent(request: OptimizationRequest): Promise<string> {
  const {
    content,
    platform,
    objective,
    targetAudience,
    tone,
    maxLength
  } = request;

  const platformGuidelines = {
    twitter: 'Keep it concise (under 280 characters), use relevant hashtags, and include a clear call-to-action.',
    instagram: 'Use engaging visual language, include relevant hashtags (5-30), and tell a story.',
    linkedin: 'Maintain professional tone, share insights or ask questions, use 3-5 hashtags.',
    facebook: 'Create engaging, conversational content that encourages comments and shares.',
    tiktok: 'Use trending language, be authentic and entertaining, include popular hashtags.'
  };

  const objectiveGuidelines = {
    engagement: 'Focus on creating content that encourages likes, comments, and shares. Ask questions, use emojis, and include interactive elements.',
    reach: 'Optimize for discoverability with relevant hashtags, trending topics, and shareable content.',
    conversions: 'Include clear call-to-actions, highlight benefits, and create urgency.',
    brand_awareness: 'Focus on brand messaging, values, and unique selling propositions.'
  };

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: `You are an expert social media content optimizer. Your task is to rewrite content to maximize ${objective} on ${platform}.

Guidelines for ${platform}: ${platformGuidelines[platform as keyof typeof platformGuidelines]}
Objective focus: ${objectiveGuidelines[objective]}

Requirements:
- Target audience: ${targetAudience}
- Tone: ${tone}
- ${maxLength ? `Maximum length: ${maxLength} characters` : ''}
- Maintain the core message while optimizing for performance
- Make it more engaging and platform-appropriate
- Include platform-specific best practices

Return only the optimized content, no explanations.`
        },
        {
          role: 'user',
          content: `Optimize this content: "${content}"`
        }
      ],
      temperature: 0.7,
      max_tokens: 500
    });

    return response.choices[0].message.content || content;
  } catch (error) {
    console.error('Content optimization error:', error);
    return content; // Return original if optimization fails
  }
}

async function generatePlatformOptimizations(
  content: string,
  platform: string,
  includeHashtags: boolean
) {
  const hashtags = includeHashtags ? await generateHashtags(content, platform) : [];
  const mentions = await generateMentions(content, platform);
  const emoji = await generateRelevantEmojis(content, platform);
  const callToAction = await generateCallToAction(content, platform);

  return {
    hashtags,
    mentions,
    emoji,
    callToAction
  };
}

async function generateHashtags(content: string, platform: string): Promise<string[]> {
  try {
    const hashtagLimits = {
      twitter: 3,
      instagram: 15,
      linkedin: 5,
      facebook: 3,
      tiktok: 8
    };

    const limit = hashtagLimits[platform as keyof typeof hashtagLimits] || 5;

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `Generate ${limit} relevant, trending hashtags for ${platform}. Return only a JSON array of hashtag strings without the # symbol. Focus on popular, searchable tags that will increase discoverability.`
        },
        {
          role: 'user',
          content: `Generate hashtags for this content: "${content}"`
        }
      ],
      temperature: 0.6,
      max_tokens: 150
    });

    const result = response.choices[0].message.content;
    if (!result) return [];

    try {
      const hashtags = JSON.parse(result);
      return Array.isArray(hashtags) ? hashtags.slice(0, limit) : [];
    } catch {
      return [];
    }
  } catch (error) {
    console.error('Hashtag generation error:', error);
    return [];
  }
}

async function generateMentions(content: string, platform: string): Promise<string[]> {
  // This would typically integrate with a database of relevant accounts/influencers
  // For now, return generic suggestions based on content analysis
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `Suggest 1-3 types of accounts that would be relevant to mention for this ${platform} content. Return suggestions like "industry_leader", "brand_partner", "influencer" rather than specific usernames.`
        },
        {
          role: 'user',
          content: `What types of accounts should be mentioned for this content: "${content}"`
        }
      ],
      temperature: 0.5,
      max_tokens: 100
    });

    const result = response.choices[0].message.content;
    return result ? result.split(',').map(s => s.trim()).slice(0, 3) : [];
  } catch {
    return [];
  }
}

async function generateRelevantEmojis(content: string, platform: string): Promise<string[]> {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `Suggest 3-5 relevant emojis for this ${platform} content. Return only the emoji characters, separated by spaces.`
        },
        {
          role: 'user',
          content: `Suggest emojis for: "${content}"`
        }
      ],
      temperature: 0.6,
      max_tokens: 50
    });

    const result = response.choices[0].message.content;
    return result ? result.split(' ').filter(e => e.trim()).slice(0, 5) : [];
  } catch {
    return ['ðŸ“±', 'ðŸ’¡', 'ðŸš€'];
  }
}

async function generateCallToAction(content: string, platform: string): Promise<string> {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `Generate a compelling call-to-action for ${platform} that encourages engagement. Keep it short and platform-appropriate.`
        },
        {
          role: 'user',
          content: `Create a CTA for this content: "${content}"`
        }
      ],
      temperature: 0.7,
      max_tokens: 50
    });

    return response.choices[0].message.content || 'What do you think?';
  } catch {
    return 'Share your thoughts below!';
  }
}

async function generateAlternativeVersions(
  content: string,
  platform: string,
  objective: string
) {
  const versions = [
    { title: 'Engagement Focused', focus: 'maximize likes, comments, and shares' },
    { title: 'Professional Tone', focus: 'maintain formal, business-appropriate language' },
    { title: 'Casual & Fun', focus: 'make it more conversational and entertaining' }
  ];

  const alternativeVersions = [];

  for (const version of versions) {
    try {
      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: `Rewrite the content for ${platform} to ${version.focus}. Keep the core message but adjust the tone and style. Return only the rewritten content.`
          },
          {
            role: 'user',
            content: content
          }
        ],
        temperature: 0.8,
        max_tokens: 300
      });

      alternativeVersions.push({
        title: version.title,
        content: response.choices[0].message.content || content,
        focus: version.focus
      });
    } catch {
      alternativeVersions.push({
        title: version.title,
        content: content,
        focus: version.focus
      });
    }
  }

  return alternativeVersions;
}

async function calculateExpectedImprovements(
  original: string,
  optimized: string,
  platform: string
) {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `You are a social media analytics expert. Compare the original and optimized content for ${platform} and estimate percentage improvements in engagement and reach. Return a JSON object with engagementIncrease, reachIncrease, and confidenceScore (all as percentages 0-100).`
        },
        {
          role: 'user',
          content: `Original: "${original}"\nOptimized: "${optimized}"`
        }
      ],
      temperature: 0.3,
      max_tokens: 150
    });

    const result = response.choices[0].message.content;
    if (result) {
      try {
        return JSON.parse(result);
      } catch {
        return {
          engagementIncrease: 25,
          reachIncrease: 15,
          confidenceScore: 75
        };
      }
    }
  } catch {
    // Fallback calculations
  }

  return {
    engagementIncrease: 20,
    reachIncrease: 10,
    confidenceScore: 70
  };
}

async function generateSEOOptimizations(content: string) {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: 'Extract 5-10 relevant keywords from this content and score readability (0-100) and sentiment (0-100, where 50 is neutral). Return JSON with keywords array, readabilityScore, and sentimentScore.'
        },
        {
          role: 'user',
          content: content
        }
      ],
      temperature: 0.3,
      max_tokens: 200
    });

    const result = response.choices[0].message.content;
    if (result) {
      try {
        return JSON.parse(result);
      } catch {
        return {
          keywords: ['content', 'social', 'media'],
          readabilityScore: 75,
          sentimentScore: 60
        };
      }
    }
  } catch {
    // Fallback
  }

  return {
    keywords: ['social media', 'content', 'engagement'],
    readabilityScore: 70,
    sentimentScore: 55
  };
}

function identifyImprovements(original: string, optimized: string, platform: string) {
  const improvements = [];

  // Check length changes
  if (optimized.length !== original.length) {
    improvements.push({
      type: 'Length Optimization',
      change: optimized.length > original.length ? 'Expanded content' : 'Shortened content',
      reason: `Optimized for ${platform} best practices`
    });
  }

  // Check for hashtag additions
  const originalHashtags = (original.match(/#\w+/g) || []).length;
  const optimizedHashtags = (optimized.match(/#\w+/g) || []).length;
  if (optimizedHashtags > originalHashtags) {
    improvements.push({
      type: 'Hashtag Enhancement',
      change: `Added ${optimizedHashtags - originalHashtags} hashtags`,
      reason: 'Improved discoverability and reach'
    });
  }

  // Check for emoji additions
  const originalEmojis = (original.match(/[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]/gu) || []).length;
  const optimizedEmojis = (optimized.match(/[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]/gu) || []).length;
  if (optimizedEmojis > originalEmojis) {
    improvements.push({
      type: 'Visual Enhancement',
      change: `Added ${optimizedEmojis - originalEmojis} emojis`,
      reason: 'Increased visual appeal and engagement'
    });
  }

  // Check for call-to-action
  const ctaWords = ['comment', 'share', 'like', 'follow', 'click', 'learn more', 'what do you think'];
  const originalHasCTA = ctaWords.some(word => original.toLowerCase().includes(word));
  const optimizedHasCTA = ctaWords.some(word => optimized.toLowerCase().includes(word));
  if (!originalHasCTA && optimizedHasCTA) {
    improvements.push({
      type: 'Call-to-Action',
      change: 'Added engagement prompt',
      reason: 'Encourage audience interaction'
    });
  }

  return improvements;
}